{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hRXQPnHzxZOw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense,Flatten,Dropout,Embedding,SimpleRNN,LSTM,SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Sentiment.csv\") #uploading data"
      ],
      "metadata": {
        "id": "f6VT22izHQ_p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[['text','sentiment']] #execlude all columns except these two columns"
      ],
      "metadata": {
        "id": "v9sjqmPuJZDq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data[data.sentiment != \"Neutral\"] #do not take the neutal rate just positve or Negaitve\n",
        "data['text'] = data['text'].apply(lambda x: x.lower()) #convert all letters to lower case\n",
        "data['text'] = data['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\s]','',x)) # do not take any charcheter out of the range of ( A - Z or a-z or 0-9)"
      ],
      "metadata": {
        "id": "4TdsA1BFJjoa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in data.iterrows():  #to remove the rt from the\n",
        "  row[0]=row[0].replace('rt','')  #to loop on all rows on colloum text"
      ],
      "metadata": {
        "id": "9tD49coxmuIB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_features=2000  #to make a tokenization in all sentences and split words in all sentences with spaces\n",
        "tokenizer = Tokenizer(num_words=max_features, split = ' ') #identifing to the tokenizer that the max words will be only 2000\n",
        "tokenizer.fit_on_texts(data['text'].values) #to appling the tokenizer on each sentence\n",
        "x=tokenizer.texts_to_sequences(data['text'].values)\n",
        "x=pad_sequences(x) #to make all sentencs have the same length so he will increase zeros to small sentences\n",
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNgZSFjQKgeM",
        "outputId": "a4255ba4-03d4-4ca9-a581-7f59d537c923"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0 ... 1301 1386  732]\n",
            " [   0    0    0 ...  231  712   17]\n",
            " [   0    0    0 ...  204  366  678]\n",
            " ...\n",
            " [   0    0    0 ...   71   65    3]\n",
            " [   0    0    0 ... 1004 1398   73]\n",
            " [   0    0    0 ...  194    3  710]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 128 #number of quetsions who the model will ask for mthe sentences in order to give the words a percentage we could use it in recognizing whom are similar\n",
        "lstm_out=196 #number of nurens of the LSTM model (Nuerons)\n",
        "\n",
        "model = Sequential() #the box whom will connected all the belopw model layers\n",
        "model.add(Embedding(max_features,embed_dim,input_length=x.shape[1]))#take the first column max sentance(10729,28)هياخد ال 28 كولوم و ياخد اطول طول جكلة فيهم ده بعدج ما عملنا tocknizier لل text\n",
        "model.add(SpatialDropout1D(0.4))#used to drop out some of neurons the layer betwen the output of the\n",
        "model.add(LSTM(lstm_out,dropout=0.2,recurrent_dropout=0.2))\n",
        "model.add(Dense(2,'softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "y = pd.get_dummies(data['sentiment']).values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV0sOe7LMb46",
        "outputId": "24ae778a-c361-47c2-feca-97adcb57c9f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQ56STGyo04z",
        "outputId": "5bbdfcfe-b643-44bb-8ca9-3c8004e144b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10729, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.3, random_state=42)\n",
        "print(x_train.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OGGFR_9PV7_",
        "outputId": "58230016-528d-4087-ee4f-63806a2296b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7510, 28) (7510, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,epochs=10,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A-5FprjQ5xI",
        "outputId": "6d4fcdeb-1f51-4b6b-97cf-8578c2d5d792"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 62s 226ms/step - loss: 0.4342 - accuracy: 0.8182\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 37s 156ms/step - loss: 0.3214 - accuracy: 0.8676\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 35s 151ms/step - loss: 0.2827 - accuracy: 0.8834\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 34s 146ms/step - loss: 0.2468 - accuracy: 0.9013\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 32s 138ms/step - loss: 0.2197 - accuracy: 0.9121\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 34s 146ms/step - loss: 0.1970 - accuracy: 0.9204\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 34s 145ms/step - loss: 0.1782 - accuracy: 0.9304\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 33s 139ms/step - loss: 0.1644 - accuracy: 0.9340\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 35s 149ms/step - loss: 0.1484 - accuracy: 0.9389\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 33s 143ms/step - loss: 0.1387 - accuracy: 0.9446\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7948847eedd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}